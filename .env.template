# Distributed AI Development System Environment Configuration Template
# Copy this to .env and customize for your setup

# Base installation directory (can be NAS/NFS shared path)
DISTRIBUTED_AI_BASE=/home/tony/AI/ROCm/distributed-ai-dev

# Key directories for agent coordination
ORCHESTRATION_DIR=${DISTRIBUTED_AI_BASE}/orchestration
REPORTS_DIR=${DISTRIBUTED_AI_BASE}/reports
TESTS_DIR=${DISTRIBUTED_AI_BASE}/tests
RESULTS_DIR=${DISTRIBUTED_AI_BASE}/orchestration/results
CONFIG_DIR=${DISTRIBUTED_AI_BASE}/config
DOCS_DIR=${DISTRIBUTED_AI_BASE}/docs
EXAMPLES_DIR=${DISTRIBUTED_AI_BASE}/examples

# Source code directories
SRC_DIR=${DISTRIBUTED_AI_BASE}/src
AGENTS_DIR=${SRC_DIR}/agents
INTERFACES_DIR=${SRC_DIR}/interfaces
CORE_DIR=${SRC_DIR}/core
KERNELS_DIR=${SRC_DIR}/kernels
PIPELINE_DIR=${SRC_DIR}/pipeline
PYTORCH_INTEGRATION_DIR=${SRC_DIR}/pytorch_integration

# ROCm repositories (NAS symlink)
ROCM_REPOS_BASE=/rust/containers/rocm-dev
ROCM_REPOS_LOCAL=/home/tony/AI/ROCm/repositories

# Agent configuration - UPDATE THESE FOR YOUR NETWORK
AGENT_113_URL=http://192.168.1.113:11434
AGENT_113_MODEL=devstral:23.6b
DEFAULT_TIMEOUT=120000

# Additional agent endpoints (customize for your setup)
KERNEL_EXPERT_URL=http://machine1:11434
KERNEL_EXPERT_MODEL=codellama:34b
PYTORCH_SPECIALIST_URL=http://machine2:11434
PYTORCH_SPECIALIST_MODEL=deepseek-coder:33b
PERFORMANCE_ANALYZER_URL=http://machine3:11434
PERFORMANCE_ANALYZER_MODEL=qwen2.5-coder:32b

# Shared workspace for multi-agent coordination
SHARED_WORKSPACE=${DISTRIBUTED_AI_BASE}/shared
SHARED_CONTEXT=${SHARED_WORKSPACE}/context
SHARED_RESULTS=${SHARED_WORKSPACE}/results

# Development settings
LOG_LEVEL=INFO
DEBUG_MODE=false
MAX_CONCURRENT_AGENTS=4

# NAS/NFS specific settings (for future expansion)
# NAS_MOUNT_POINT=/mnt/nas/distributed-ai-dev
# NFS_EXPORT_PATH=/exports/distributed-ai-dev
