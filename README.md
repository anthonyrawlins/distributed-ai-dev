# Distributed AI Development System

A powerful coordination system that enables Claude (or other AI coordinators) to orchestrate multiple local AI agents for distributed software development, specifically optimized for ROCm and GPU computing projects.

## ðŸš€ **Features**

- **AI Agent Coordination** - Orchestrate multiple Ollama agents across your network
- **Specialized Agents** - Kernel developers, PyTorch experts, profilers, testers, and documentation writers
- **Quality Control** - Multi-agent code review and validation systems
- **Claude Integration** - Easy interface for Claude to manage distributed development
- **Cost Efficient** - Reduce Claude usage by 90% while scaling development capacity
- **Production Ready** - Comprehensive testing, monitoring, and deployment tools

## ðŸŽ¯ **Perfect For**

- **ROCm/GPU Development** - Optimize CUDA/HIP kernels, attention mechanisms, VAE decoders
- **ML Framework Integration** - PyTorch, TensorFlow, and custom framework development  
- **Performance Optimization** - Memory management, kernel fusion, multi-GPU coordination
- **Distributed Teams** - Scale development across multiple AI agents and compute resources

## ðŸ“‹ **Quick Start**

### 1. Installation

```bash
git clone https://github.com/anthonyrawlins/distributed-ai-dev.git
cd distributed-ai-dev
pip install aiohttp asyncio dataclasses
```

### 2. Configure Your Agents

Edit your agent endpoints in `src/interfaces/claude_interface.py`:

```python
AGENT_CONFIG = [
    {
        'id': 'kernel_expert',
        'endpoint': 'http://192.168.1.100:11434',
        'model': 'codellama:34b',
        'specialty': 'kernel_dev',
        'max_concurrent': 2
    },
    {
        'id': 'pytorch_specialist', 
        'endpoint': 'http://192.168.1.101:11434',
        'model': 'deepseek-coder:33b',
        'specialty': 'pytorch_dev',
        'max_concurrent': 2
    }
]
```

### 3. Test the System

```bash
python tests/test_distributed_system.py
```

### 4. Start Using from Claude

```python
from src.interfaces.claude_interface import setup_development_network, delegate_work

# Setup your agent network
await setup_development_network(YOUR_AGENT_CONFIG)

# Delegate complex development work
result = await delegate_work(
    "Optimize FlashAttention kernel for RDNA3",
    files=["attention.cpp", "kernels.hip"], 
    priority=5
)

# Check progress
progress = await check_progress()
results = await collect_results()
```

## ðŸ—ï¸ **Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Claude        â”‚    â”‚   Coordinator    â”‚    â”‚  Quality        â”‚
â”‚   Interface     â”‚â—„â”€â”€â–ºâ”‚   System         â”‚â—„â”€â”€â–ºâ”‚  Control        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚          â”‚          â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ Kernel   â”‚ â”‚PyTorch  â”‚ â”‚Profiler â”‚
              â”‚ Agent    â”‚ â”‚ Agent   â”‚ â”‚ Agent   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ¤– **Agent Specializations**

### **Kernel Developer** (`kernel_dev`)
- **Models**: CodeLlama-34B, DeepSeek-Coder-33B
- **Focus**: HIP kernels, CUDA ports, CK templates, GPU optimization
- **Output**: Optimized kernels with performance analysis

### **PyTorch Developer** (`pytorch_dev`)
- **Models**: Qwen2.5-Coder-32B, DeepSeek-Coder
- **Focus**: PyTorch integration, autograd, TunableOp, Python bindings
- **Output**: Production-ready PyTorch code with tests

### **Performance Profiler** (`profiler`)
- **Models**: Llama-3.1-70B, Qwen2.5-Coder
- **Focus**: rocprof analysis, benchmarking, bottleneck identification
- **Output**: Performance reports with optimization recommendations

### **Documentation Writer** (`docs_writer`)
- **Focus**: API docs, tutorials, installation guides
- **Output**: Clear documentation with examples

### **Tester** (`tester`)
- **Focus**: Unit tests, integration tests, CI/CD
- **Output**: Comprehensive test suites

## ðŸ“Š **Example Workflow**

1. **Claude analyzes** your optimization request (e.g., "Optimize Stable Diffusion for ROCm")
2. **Breaks down** into specialized subtasks:
   - Kernel optimization â†’ Kernel Developer Agent
   - PyTorch integration â†’ PyTorch Developer Agent  
   - Performance analysis â†’ Profiler Agent
   - Documentation â†’ Documentation Writer Agent
3. **Delegates** tasks to appropriate agents in parallel
4. **Monitors progress** and coordinates between agents
5. **Reviews results** with quality control system
6. **Integrates solutions** and creates final deliverable

## ðŸ”§ **Project Structure**

```
distributed-ai-dev/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ ai_dev_coordinator.py      # Main coordination system
â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â””â”€â”€ claude_interface.py        # Claude integration interface
â”‚   â”œâ”€â”€ quality/
â”‚   â”‚   â””â”€â”€ quality_control.py         # Multi-agent code review
â”‚   â””â”€â”€ agents/
â”‚       â”œâ”€â”€ agent_113_config.py        # Agent-specific configurations
â”‚       â””â”€â”€ monitor_agent_113.py       # Agent monitoring tools
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_distributed_system.py     # System integration tests
â”‚   â”œâ”€â”€ test_agent_113.py             # Agent-specific tests
â”‚   â””â”€â”€ quick_agent_integration.py     # Quick validation tests
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ agent_113_workload.py         # Example workload management
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ setup_guide.md                # Detailed setup instructions
â”‚   â”œâ”€â”€ distributed-ai-dev-system.md  # System architecture
â”‚   â”œâ”€â”€ daily-contribution-plan.md    # Development workflow
â”‚   â””â”€â”€ rocm-planning.md              # ROCm optimization roadmap
â”œâ”€â”€ README.md                          # This file
â””â”€â”€ LICENSE                           # MIT License
```

## ðŸ“ˆ **Benefits**

- **90% Cost Reduction** - Minimize Claude usage for development tasks
- **Parallel Development** - Multiple agents working simultaneously
- **24/7 Capability** - Agents work continuously
- **Quality Assured** - Multi-agent review process
- **Scalable** - Easily add more agents and specializations
- **Production Ready** - Comprehensive testing and monitoring

## ðŸ› ï¸ **Configuration**

### **Recommended Models by GPU Memory:**

- **8GB VRAM**: CodeLlama-13B, DeepSeek-Coder-6.7B, Qwen2.5-Coder-14B
- **16GB VRAM**: CodeLlama-34B, DeepSeek-Coder-33B, Qwen2.5-Coder-32B  
- **24GB+ VRAM**: Llama-3.1-70B, DevStral-23B (for complex analysis)

### **Performance Tuning:**
- Set `max_concurrent=1` for large models (>20B parameters)
- Use `max_concurrent=2-3` for smaller models (<15B parameters)
- Adjust `temperature=0.1` for consistent code generation
- Set appropriate `max_tokens` based on task complexity

## ðŸš¨ **Important Notes**

- **Always review** agent-generated code before committing
- **Test thoroughly** on your specific hardware setup
- **Start small** with simple optimizations to validate the system
- **Monitor resource usage** across your agent network
- **Keep backups** of working configurations

## ðŸ“š **Documentation**

- [Setup Guide](docs/setup_guide.md) - Detailed installation and configuration
- [System Architecture](docs/distributed-ai-dev-system.md) - Technical deep dive
- [Daily Workflow](docs/daily-contribution-plan.md) - Development processes
- [ROCm Optimization](docs/rocm-planning.md) - Specific ROCm development strategy

## ðŸ¤ **Contributing**

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ðŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸŽ¯ **Success Stories**

This system was designed for and tested with:
- **ROCm optimization projects** targeting RDNA3/CDNA3 architectures
- **Stable Diffusion performance improvements** on AMD GPUs
- **FlashAttention kernel development** for PyTorch
- **VAE decoder optimization** for computer vision workloads
- **Multi-GPU memory management** systems

## â­ **Star this repo if it helps accelerate your development!**

---

**Transform your local compute network into a distributed AI development team! ðŸš€**